
%% (1) OLS
clear all;clc
M=10000;                              %number of sequences
for i = 1:M
    %DGP
    T = 100;
    u = randn(T,1);
    x = zeros(T,1);
    for k = 2:T
        x(k) = x(k-1)+u(k);
    end
    clear k;
    %assign regression variables
    y = x([2:T]);
    X = x([1:T-1]);
    %OLS estimate
    rho=(X'*X)\X'*y;
    % Calculates regression statistics
    e = y - X*rho;                      %white noise
    SSE = e'*e;                         %SSE (Sum of Square Errors)
    var_e = SSE/(T-1);                  %sample variance of white noise
    var_rho = sqrt(inv(X'*X)*var_e);    %Variance of the OLS estimate
    sigma_rho1 = (diag(var_rho));        %Standard Error of the estimates
    t_ratio1(i) = (rho-1)/sigma_rho1;     %t-ratio for rho is one
end
clear i;
%prob = 1-tpdf(t_ratio,T-1);             %prob that rho is one
output = prctile(t_ratio1,0.06);
fprintf('6th percentile of t-ratios in first case:\n');
disp(output);

%% (2) OLS with intercept
M=10000;                              %number of sequences
for i = 1:M
    %DGP
    T = 100;
    u = randn(T,1);
    x = zeros(T,1);
    for k = 2:T
        x(k) = x(k-1)+u(k);
    end
    clear k;
    %assign regression variables
    y = x([2:T]);
    X = [ones(T-1,1) x([1:T-1])];
    %OLS estimate
    rho=(X'*X)\X'*y;
    % Calculates regression statistics
    e = y - X*rho;                      %white noise
    SSE = e'*e;                         %SSE (Sum of Square Errors)
    var_e = SSE/(T-2);                  %sample variance of white noise
    var_rho = sqrt(inv(X'*X)*var_e);    %Variance of the OLS estimate
    sigma_rho = (diag(var_rho));        %Standard Error of the estimates
    t_ratio2(i)=(rho(2)-1)/sigma_rho(2); %t-ratio for rho is one
end
clear i;
output = prctile(t_ratio2,0.06);
fprintf('\n6th percentile of t-ratios in second case:\n');
disp(output)

%% (3) OLS with intercept and time trend
M=10000;                              %number of sequences
for i = 1:M
    %DGP
    T = 100;
    u = randn(T,1);
    x = zeros(T,1);
    for k = 2:T
        x(k) = x(k-1)+u(k);
    end
    clear k;
    %assign regression variables
    y = x([2:T]);
    t = 1:(T-1);
    X = [ones(T-1,1) x([1:T-1]) t'];
    %OLS estimate
    rho=(X'*X)\X'*y;
    % Calculates regression statistics
    e = y - X*rho;                      %white noise
    SSE = e'*e;                         %SSE (Sum of Square Errors)
    var_e = SSE/(T-2);                  %sample variance of white noise
    var_rho = sqrt(inv(X'*X)*var_e);    %Variance of the OLS estimate
    sigma_rho = (diag(var_rho));        %Standard Error of the estimates
    t_ratio3(i)=(rho(2)-1)/sigma_rho(2); %t-ratio for rho is one
end
clear i;
output = prctile(t_ratio3,0.06);
fprintf('\n6th percentile of t-ratios in third case:\n');
disp(output)


%% Global variables
clear all;clc;
global p
p = 0.98;
global c;
c = 0.3;
%% For T = 50
M = 10000;              %number of sequences
t_ratio=zeros(M,1);
for i = 1:M
    %DGP
    T = 50;
    u = randn(T,1);
    x = zeros(T,1);
    x(1) = c/(1-p);
    for k = 2:T
        x(k) = c + p*x(k-1) + u(k); %AR(1) process
    end
    clear k;
    %assign regression variables
    y = x([2:T]);
    X = [ones(T-1,1) x([1:T-1])];
    %OLS estimate
    rho=(X'*X)\X'*y;
    % Calculates regression statistics
    e = y - X*rho;                      %white noise
    SSE = e'*e;                         %SSE (Sum of Square Errors)
    var_u = SSE/(T-2);                  %sample variance of white noise
    var_rho = sqrt(inv(X'*X)*var_u);    %Variance of the OLS estimate
    sigma_rho = (diag(var_rho));        %Standard Error of the estimates
    t_ratio(i)=(rho(2)-p)/sigma_rho(2); %t-ratio for rho is one
end
clear i;
output = prctile(t_ratio,0.05);
fprintf('\n5th percentile of t-ratios for T=%d:\n',T);
disp(output)
%% For T = 100
M = 10000;              %number of sequences
t_ratio=zeros(M,1);
for i = 1:M
    %DGP
    T = 100;
    u = randn(T,1);
    x = zeros(T,1);
    x(1) = c/(1-p);
    for k = 2:T
        x(k) = c + p*x(k-1) + u(k); %AR(1) process
    end
    clear k;
    %assign regression variables
    y = x([2:T]);
    X = [ones(T-1,1) x([1:T-1])];
    %OLS estimate
    rho=(X'*X)\X'*y;
    % Calculates regression statistics
    e = y - X*rho;                      %white noise
    SSE = e'*e;                         %SSE (Sum of Square Errors)
    var_u = SSE/(T-2);                  %sample variance of white noise
    var_rho = sqrt(inv(X'*X)*var_u);    %Variance of the OLS estimate
    sigma_rho = (diag(var_rho));        %Standard Error of the estimates
    t_ratio(i)=(rho(2)-p)/sigma_rho(2); %t-ratio for rho is one
end
clear i;
output = prctile(t_ratio,0.05);
fprintf('\n5th percentile of t-ratios for T=%d:\n',T);
disp(output)
%% For T = 250
M = 10000;              %number of sequences
t_ratio=zeros(M,1);
for i = 1:M
    %DGP
    T = 200;
    u = randn(T,1);
    x = zeros(T,1);
    x(1) = c/(1-p);
    for k = 2:T
        x(k) = c + p*x(k-1) + u(k); %AR(1) process
    end
    clear k;
    %assign regression variables
    y = x([2:T]);
    X = [ones(T-1,1) x([1:T-1])];
    %OLS estimate
    rho=(X'*X)\X'*y;
    % Calculates regression statistics
    e = y - X*rho;                      %white noise
    SSE = e'*e;                         %SSE (Sum of Square Errors)
    var_u = SSE/(T-2);                  %sample variance of white noise
    var_rho = sqrt(inv(X'*X)*var_u);    %Variance of the OLS estimate
    sigma_rho = (diag(var_rho));        %Standard Error of the estimates
    t_ratio(i)=(rho(2)-p)/sigma_rho(2); %t-ratio for rho is one
end
clear i;
output = prctile(t_ratio,0.05);
fprintf('\n5th percentile of t-ratios for T=%d:\n',T);
disp(output)
%% For T = 500
M = 10000;              %number of sequences
t_ratio=zeros(M,1);
for i = 1:M
    %DGP
    T = 500;
    u = randn(T,1);
    x = zeros(T,1);
    x(1) = c/(1-p);
    for k = 2:T
        x(k) = c + p*x(k-1) + u(k); %AR(1) process
    end
    clear k;
    %assign regression variables
    y = x([2:T]);
    X = [ones(T-1,1) x([1:T-1])];
    %OLS estimate
    rho=(X'*X)\X'*y;
    % Calculates regression statistics
    e = y - X*rho;                      %white noise
    SSE = e'*e;                         %SSE (Sum of Square Errors)
    var_u = SSE/(T-2);                  %sample variance of white noise
    var_rho = sqrt(inv(X'*X)*var_u);    %Variance of the OLS estimate
    sigma_rho = (diag(var_rho));        %Standard Error of the estimates
    t_ratio(i)=(rho(2)-p)/sigma_rho(2); %t-ratio for rho is one
end
clear i;
output = prctile(t_ratio,0.05);
fprintf('\n5th percentile of t-ratios for T=%d:\n',T);
disp(output)


%% Loading the data
clear all;clc;
addpath(genpath('C:/Program Files/MATLAB/R2013b/bin/Projects/MFE'));
[data,date] =xlsread('US real GDP', 'A8:B274');
y = log(data);           %logging the series
T = length(data);        %number of data points
dy = zeros(T-1,1);
for i = 1:(T-1)
    dy(i) = y(i+1) - y(i);
end
clear i
% fitting an AR(2) model
p = 2;     %AR part
q = 0;     %MA part
param = armaxfilter(dy,1,[1:p],[1:q]);    %calculate parameters
const = param(1);
alpha1 = param(2);
alpha2 = param(3);
mu = const/(1-alpha1-alpha2);
%Calculate WN
% for i = 3:(T-1)
%     u(i,1) = dy(i) - alpha1*dy(i-1) - alpha2*dy(i-2);
% end
% clear i;
%% Beveridge-Nelson decomposition
%splitting dy in its permanent and transitory components
%psi(L) = beta(L)/alpha(L)
psi1 = 1/(1 - alpha1 - alpha2);
for t = 3:T
    yP_BN(t,1) = (y(t) -alpha1*y(t-1) -alpha2*y(t-2))*psi1;
end
clear t;
yT_BN = y - yP_BN;

%%Hodrick-Prescott decomposition
lambda = 1600;              % due to quarterly data
[yP_HP,yT_HP] = hp_filter(y,lambda);

%% Plot the data
%Permanent part = trend
subplot(1,3,1)
plot(3:T,yP_BN(3:end),'r');
hold on
plot(1:T,yP_HP,'b');
ylabel('Permanent component')
xlabel('Time')
hold off
legend('BN','HP')
% Transitory part = cycle
subplot(1,3,2)
plot(3:T,yT_BN(3:end),'r');
hold on
plot(1:T,yT_HP,'b');
ylabel('Transitory component')
xlabel('Time')
hold off
legend('BN','HP')
subplot(1,3,3);
plot(1:T,y,'g')
ylabel('Orignal Series');
xlabel('Time');

%% VAR(2) calculations
clear all;clc;clf;
%parameters
k = 3;          % #variables
p = 2;          % #lags
A1 =[.7 .1 0;0 .4 .1; .9 0 .8];  %1.lag parameter matrix
A2 =[-.2 0 0;0 .1 .1;0 0 0];     %2.lag parameter matrix
c =[1;2;2];     %constant
cov=[.25 .05 0;.05 .1 0;0 0 .81];%VarCov matrix for u


%in companion form
Ik = eye(k);
Ok = zeros(k,k);
A =[A1 A2;Ik Ok];
C =[c;Ok(:,1)];
Cov =[cov Ok; Ok Ok];
S =[Ik Ok];

%lagploynomial (I - A1L - A2L)
syms z
AL = Ik - A1*z - A2*z^2; % symbolic polynomial
detAL = det(AL); % det of symbolic polynomial

%% Determining Stationarity
% convert back to numerical polynomial
lag_roots = roots(sym2poly(detAL));
fprintf('Roots of Lag-polynomial:\n');
% disp(lag_roots);
if abs(lag_roots)>1
    fprintf('Values of z are all greater than one, thus the system is stationary\n')
else
    fprintf('Values of z are NOT all greater than one, thus the system is NOT stationary\n')
end

% compute eig(A)
eigA = eig(A);
fprintf('\nRoots of charactistic-polynomial:\n');
% disp(eigA);
if eig(A)<1
    fprintf('Eigenvalues of A are all smaller than one, thus the system is stationary\n')
else
    fprintf('Eigenvalues of A are NOT all smaller than one, thus the system is NOT stationary\n')
end

%% unconditional mean
mu = (Ik - A1 - A2)\c;
fprintf('\nUnconditional mean:\n');
disp(mu);

%% variance/covariance matrix
Gam0 = reshape((eye((p*k)^2)-kron(A,A))\Cov(:),p*k,p*k);
gam0 = Gam0(1:3,1:3);
gam1 = Gam0(1:3,4:6);
fprintf('Variance:\n');
disp(gam0);

%% Cholesky decomposition and IRF
P = chol(cov);
% Impulse response functions
phiL = AL\P;        %psiL*AL where psiL is the MA(inf) representation
W = (P)\cov;        %P-1*cov
Atil = A1*1 - A2*1^2;
F= 20;
for i = 1:F
    psi(:,:,i) = S*A^i*S';
    phi(:,:,i) = psi(:,:,i)*P;
end
% plot the IRF
figure(1);
pi1=permute(phi(1,1,:),[3,1,2]);
pi2=permute(phi(2,1,:),[3,1,2]);
pi3=permute(phi(3,1,:),[3,1,2]);
subplot(1,3,1);
plot(1:F,pi1);
hold on
plot(1:F,pi2,'r-');
plot(1:F,pi3,'g');
legend('u1','u2','u3');
ylabel('Shock on Inflation Pi')
xlabel('Impulse Response Function #');
hold off

y1=permute(phi(1,2,:),[3,1,2]);
y2=permute(phi(2,2,:),[3,1,2]);
y3=permute(phi(3,2,:),[3,1,2]);
subplot(1,3,2);
plot(1:F,y1)
hold on
plot(1:F,y2,'r')
plot(1:F,y3,'g')
legend('u1','u2','u3')
ylabel('Shock on Output Growth Y')
xlabel('Impulse Response Function #');
hold off

m1=permute(phi(1,3,:),[3,1,2]);
m2=permute(phi(2,3,:),[3,1,2]);
m3=permute(phi(3,3,:),[3,1,2]);
subplot(1,3,3);
plot(1:F,m1)
hold on
plot(1:F,m2,'r')
plot(1:F,m3,'g')
legend('u1','u2','u3')
ylabel('Shock on Money Growth M')
xlabel('Impulse Response Function #');
hold off

%% Forecasting
H = 20;             % time horizon for forecasting
Xt = [mu; mu];     %initial values for loop

%loop for the forecasting repetition
for h= 1:H
    Xt_h(:,h) = mu + (S*A^h)*Xt;
end
%plot the forecast
figure(2);
plot(1:H,Xt_h(1,:));
hold on
plot(1:H,Xt_h(2,:),'r');
plot(1:H,Xt_h(3,:),'g');
legend('pi','y','m');
hold off
